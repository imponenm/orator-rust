What happens when generate is called?

1. Self text_encoder (T5EncoderModel) calls forward()

2. Model calls self.decoder.forward()
2a. self.decoder.forward() iterates through Decoder's self Vec<DecoderLayer>
2b. Each DecoderLayer calls its self.forward() function
  2c. self.self_attn.forward() finally updates self.self_attn's Attention object's kv_cache
  2d. self.cross_attn.forward() finally updates self.self_attn's Attention object's kv_cache


- The Model object I declare has a member variable 'decoder' of type Decoder.
- TODO: Decoder has a 'layers' member variable of type Vec<DecoderLayer>. I think I need to create a layer's object to pass into the generate function, and modify Decoder's constructor and forward function to use the given Vec<DecoderLayer>
  - When Decoder is initialized, it creates a new DecoderLayer for every num_hidden_layers in its DecoderConfig that gets passed to it


##### Decoder #####

Ya, so I'm very confident I just need to create my own layers object of type Vec<DecodeLayer>

##### Text Encoder #####


I make a call to self.text_encoder.forward(). text_encoder is type T5EncoderModel

T5EncoderModel has an encoder member variable of type T5Stack. The T5EncoderModel's forward function calls T5Stack's forward function

T5Stack's forward function takes a mutable refernce to self, so this is where the issue starts. There's a call to iter_mut() and clear_kv_cache() to investigate

Both these functions affect a block member variable of type Vec<T5Block>

T5Block has a clear_kv_cache() call to fix, and also a forward() call using a T5LayerCrossAttention

T5LayerCrossAttention is the last of it


------
This is basically the same thing

T5Stack has a vector of T5Block's, and those T5Blocks have two kv_caches. One is self_attn, the other cross_attn